{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "# satellite APIs and geospatial libraries are not needed, since we start with numpy arrays\n",
    "#import geopy.distance as distance\n",
    "#import geopandas as gpd\n",
    "#from shapely.geometry import Point\n",
    "\n",
    "#import rioxarray\n",
    "#from IPython.display import Image\n",
    "#from PIL import Image as PILImage\n",
    "\n",
    "#import planetary_computer as pc\n",
    "#from pystac_client import Client\n",
    "#import odc.stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "import image_modeling    # own file\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSEED = image_modeling.RSEED\n",
    "\n",
    "NUM_LAYERS = image_modeling.NUM_LAYERS\n",
    "IMAGE_SIZE = image_modeling.IMAGE_SIZE\n",
    "IMG_SHAPE = image_modeling.IMG_SHAPE\n",
    "NUM_TOTAL_VALUES = image_modeling.NUM_TOTAL_VALUES\n",
    "DTYPE = image_modeling.DTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to the data folder\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data\"\n",
    "assert DATA_DIR.exists()\n",
    "\n",
    "MODEL_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>1614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3</td>\n",
       "      <td>111825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aafl</td>\n",
       "      <td>39.474744</td>\n",
       "      <td>-86.898353</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>4</td>\n",
       "      <td>2017313.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid   latitude  longitude        date  split   region  severity    density\n",
       "0  aabm  39.080319 -86.430867  2018-05-14  train  midwest         1      585.0\n",
       "1  aacd  35.875083 -78.878434  2020-11-19  train    south         1      290.0\n",
       "2  aaee  35.487000 -79.062133  2016-08-24  train    south         1     1614.0\n",
       "3  aaff  38.049471 -99.827001  2019-07-23  train  midwest         3   111825.0\n",
       "4  aafl  39.474744 -86.898353  2021-08-23  train  midwest         4  2017313.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial entries in dataset:  17060\n",
      "Remaining entries in dataset:  17055\n"
     ]
    }
   ],
   "source": [
    "# remove id's where no sat images could be collected\n",
    "print(\"Initial entries in dataset: \", len(df))\n",
    "errored_ids = ['einx', 'gygq', 'ifwc', 'jdvp', 'qpeh', 'tgiq', 'wrqa']\n",
    "for id in errored_ids:\n",
    "    df.drop(df.loc[df['uid']==id].index, inplace=True)\n",
    "print(\"Remaining entries in dataset: \", len(df))\n",
    "image_count = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1</td>\n",
       "      <td>585.0</td>\n",
       "      <td>/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aabm.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>290.0</td>\n",
       "      <td>/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aacd.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aaee.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3</td>\n",
       "      <td>111825.0</td>\n",
       "      <td>/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aaff.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aafl</td>\n",
       "      <td>39.474744</td>\n",
       "      <td>-86.898353</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>train</td>\n",
       "      <td>midwest</td>\n",
       "      <td>4</td>\n",
       "      <td>2017313.0</td>\n",
       "      <td>/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aafl.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid   latitude  longitude        date  split   region  severity  \\\n",
       "0  aabm  39.080319 -86.430867  2018-05-14  train  midwest         1   \n",
       "1  aacd  35.875083 -78.878434  2020-11-19  train    south         1   \n",
       "2  aaee  35.487000 -79.062133  2016-08-24  train    south         1   \n",
       "3  aaff  38.049471 -99.827001  2019-07-23  train  midwest         3   \n",
       "4  aafl  39.474744 -86.898353  2021-08-23  train  midwest         4   \n",
       "\n",
       "     density  \\\n",
       "0      585.0   \n",
       "1      290.0   \n",
       "2     1614.0   \n",
       "3   111825.0   \n",
       "4  2017313.0   \n",
       "\n",
       "                                                                                     path  \n",
       "0  /Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aabm.npy  \n",
       "1  /Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aacd.npy  \n",
       "2  /Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aaee.npy  \n",
       "3  /Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aaff.npy  \n",
       "4  /Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/aafl.npy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add filepaths to dataframe\n",
    "def get_path(id):\n",
    "   return str(DATA_DIR/'sat_images/image_arrays_8_layer/') + f\"/{id}.npy\"\n",
    "\n",
    "df['path'] = df[\"uid\"].apply(get_path)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in train dataset:  13644\n",
      "Samples in evaluation dataset:  1705\n",
      "Samples in test dataset:  1706\n",
      "Total samples:  17055\n"
     ]
    }
   ],
   "source": [
    "# shuffle dataframe and create train/val/test splits\n",
    "df_shuffled = df.sample(frac=1, random_state=RSEED, ignore_index=True)\n",
    "df_train = df_shuffled.iloc[0:int(image_count * 0.8)].reset_index(drop=True)\n",
    "df_eval   = df_shuffled.iloc[int(image_count * 0.8 ):int(image_count * 0.9)].reset_index(drop=True)\n",
    "df_test  = df_shuffled.iloc[int(image_count * 0.9 ):].reset_index(drop=True)\n",
    "\n",
    "print('Samples in train dataset: ', len(df_train))\n",
    "print('Samples in evaluation dataset: ', len(df_eval))\n",
    "print('Samples in test dataset: ', len(df_test))\n",
    "print('Total samples: ', len(df_test) + len(df_train) + len(df_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write .csv files with image paths and density (target value)\n",
    "ALL_PATH   = MODEL_DIR / \"file_list_all.csv\"\n",
    "TRAIN_PATH = MODEL_DIR / \"file_list_train.csv\"\n",
    "EVAL_PATH  = MODEL_DIR / \"file_list_eval.csv\"\n",
    "TEST_PATH  = MODEL_DIR / \"file_list_test.csv\"\n",
    "\n",
    "df[['path','density']].to_csv(ALL_PATH, index=False, header=False)\n",
    "df_train[['path','density']].to_csv(TRAIN_PATH, index=False, header=False)\n",
    "df_eval[['path','density']].to_csv(EVAL_PATH, index=False, header=False)\n",
    "df_test[['path','density']].to_csv(TEST_PATH, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = DATA_DIR / 'sat_images/image_arrays_8_layer/aabm.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_filepaths = [str(DATA_DIR/'sat_images/image_arrays_8_layer/') + f\"/{id}.npy\" for id in DATASET.uid.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_ds = tf.data.Dataset.list_files(str(DATA_DIR/'sat_images/image_arrays_8_layer/*.npy'), shuffle=False)\n",
    "#list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check that filenames are correct\n",
    "# for f in list_ds.take(5):\n",
    "#   print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def npy_header_offset(npy_path):\n",
    "#     with open(str(npy_path), 'rb') as f:\n",
    "#         if f.read(6) != b'\\x93NUMPY':\n",
    "#             raise ValueError('Invalid NPY file.')\n",
    "#         version_major, version_minor = f.read(2)\n",
    "#         if version_major == 1:\n",
    "#             header_len_size = 2\n",
    "#         elif version_major == 2:\n",
    "#             header_len_size = 4\n",
    "#         else:\n",
    "#             raise ValueError('Unknown NPY file version {}.{}.'.format(version_major, version_minor))\n",
    "#         header_len = sum(b << (8 * i) for i, b in enumerate(f.read(header_len_size)))\n",
    "#         header = f.read(header_len)\n",
    "#         if not header.endswith(b'\\n'):\n",
    "#             raise ValueError('Invalid NPY file.')\n",
    "#         return f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for our files the header length is always 128 bytes\n",
    "# header_offset = npy_header_offset(test_path)\n",
    "# print(header_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_target_value(file_path):\n",
    "#   # Convert the path to a list of path components\n",
    "#   parts = tf.strings.split(file_path, os.path.sep)\n",
    "#   # take the id from the filename\n",
    "#   id = tf.strings.split(parts[-1], '.')[0]\n",
    "#   # get the density value for this id from the dataset\n",
    "#   target_value = DATASET.loc[DATASET['uid']==id]['density'].values[0]\n",
    "#   return tf.constant(target_value, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try out the function\n",
    "#get_target_value(test_path).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_dataset = tf.data.FixedLengthRecordDataset(\n",
    "#     list_of_filepaths, \n",
    "#     NUM_TOTAL_VALUES * DTYPE.size, \n",
    "#     header_bytes=header_offset, \n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reshape(tf.io.decode_raw(img, DTYPE), IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maybe do this after batching ???\n",
    "\n",
    "# tf_dataset = tf_dataset.map(lambda s: \n",
    "# tf_dataset = tf_dataset.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfimg = tf.io.read_file(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfimg = tf.io.decode_raw(tfimg, tf.float32)[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfimg = tf.reshape(tfimg, [NUM_LAYERS, IMAGE_SIZE, IMAGE_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfimg[32:]) # npy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.FixedLengthRecordDataset(\n",
    "#         filenames=[test_path],\n",
    "#         record_bytes=NUM_TOTAL_VALUES * DTYPE.size, \n",
    "#         header_bytes=128\n",
    "#     )\n",
    "# image_bytes = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatype_bits = 32\n",
    "# remove_len = 1024//datatype_bits\n",
    "# tfimg = tfimg[remove_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = tf.reshape(tf.io.decode_raw(image_bytes, DTYPE), IMG_SHAPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = tf_dataset.take(1).as_numpy_iterator()\n",
    "# object = iterator.next()\n",
    "# print(object.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RGB image from individual channels and masked image from masked channels\n",
    "# rgb_image = np.array(\n",
    "#         [object[0],\n",
    "#          object[1],\n",
    "#          object[2]]\n",
    "#         )\n",
    "# masked_image = np.array(\n",
    "#         [object[4],\n",
    "#          object[5],\n",
    "#          object[6]]\n",
    "#         )\n",
    "# # show normalized image (range shifted to approximately 0-255, no hard limit though)\n",
    "# plt.figure(figsize=(14,6))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(np.transpose((rgb_image), axes=[1, 2, 0]));\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(np.transpose((masked_image), axes=[1, 2, 0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(img))\n",
    "# print(img.get_shape())\n",
    "# np_array = tf.io.decode_raw(img, DTYPE, ).numpy()\n",
    "# np_array.reshape((NUM_LAYERS, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_img(img):\n",
    "#   # Convert the compressed string to a 3D uint8 tensor\n",
    "#   img = tf.io.decode_jpeg(img, channels=3)\n",
    "#   # Resize the image to the desired size\n",
    "#   return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_path(file_path):\n",
    "#   target = get_target_value(file_path)\n",
    "#   # Load the raw data from the file as a string\n",
    "#   img = tf.io.read_file(file_path)\n",
    "#   img = decode_img(img)\n",
    "#   return img, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import variables from image_modelling.py file\n",
    "HEIGHT = image_modeling.HEIGHT\n",
    "WIDTH = image_modeling.WIDTH\n",
    "BATCH_SIZE = image_modeling.BATCH_SIZE\n",
    "TRAINING_SIZE = len(df_train) #!wc -l < flowers_train.csv\n",
    "#TRAINING_STEPS = int(TRAINING_SIZE[0]) // BATCH_SIZE\n",
    "TRAINING_STEPS = TRAINING_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a simple linear model.\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(\n",
    "        input_shape=IMG_SHAPE, \n",
    "        #input_shape=[HEIGHT, WIDTH, 3], \n",
    "        name='image'\n",
    "        ))\n",
    "    model.add(tf.keras.layers.Flatten(data_format=\"channels_last\"))\n",
    "    # We want to have a simple linear model so we have \n",
    "    # no activation function. \n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for training and evaluation\n",
    "def train_and_evaluate(model, batch_size):\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        ##loss=tf.keras.losses.MeanSquaredError(),\n",
    "        #loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        loss='mse',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    dataset = image_modeling.load_dataset(TRAIN_PATH, batch_size)\n",
    "    eval_dataset = image_modeling.load_dataset(EVAL_PATH, batch_size, training=False)\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model.fit(\n",
    "        dataset, \n",
    "        validation_data=eval_dataset,\n",
    "        #steps_per_epoch=TRAINING_STEPS, \n",
    "        epochs=10,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a testing function.\n",
    "def test(model):\n",
    "    \n",
    "    test_dataset = image_modeling.load_dataset(TEST_PATH, batch_size=1, training=False)\n",
    "    model.evaluate(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if loading works correctly\n",
    "# dataset1 = image_modeling.load_dataset(TRAIN_PATH, BATCH_SIZE)\n",
    "# elem = next(iter(dataset1))\n",
    "# print(elem[0][0][0].shape)\n",
    "# elem[1][5].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rgb_image = np.array(\n",
    "#         [elem[0][17][0],\n",
    "#          elem[0][17][1],\n",
    "#          elem[0][17][2]]\n",
    "#         )\n",
    "# # show normalized image (range shifted to approximately 0-255, no hard limit though)\n",
    "# plt.figure(figsize=(14,6))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(np.transpose((rgb_image), axes=[1, 2, 0]));\n",
    "# #plt.subplot(122)\n",
    "# #plt.imshow(np.transpose((masked_image), axes=[1, 2, 0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(df[df[\"date\"] > \"2015-07-01\"].uid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = next(it)\n",
    "# filepath = f'/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/{id}.npy'\n",
    "# loaded_layers = np.load(filepath)\n",
    "# water_pixels = (loaded_layers[4] > 0.0).sum()\n",
    "# mean_r  = loaded_layers[4].sum()/(water_pixels) if (water_pixels > 0) else 0.0\n",
    "# mean_g  = loaded_layers[5].sum()/(water_pixels) if (water_pixels > 0) else 0.0\n",
    "# mean_b  = loaded_layers[6].sum()/(water_pixels) if (water_pixels > 0) else 0.0\n",
    "# mean_ir = loaded_layers[7].sum()/(water_pixels) if (water_pixels > 0) else 0.0\n",
    "# print('ID: ', id)\n",
    "# print('Max value in masked image: ', loaded_layers[4:].max())\n",
    "# print('Water pixels: ', water_pixels)\n",
    "# print('Density: ', df[df['uid'] == id].density.values[0])\n",
    "# print('Mean R:  ', mean_r)\n",
    "# print('Mean G:  ', mean_g)\n",
    "# print('Mean B:  ', mean_b)\n",
    "# print('Mean IR: ', mean_ir)\n",
    "\n",
    "# # RGB image from individual channels and masked image from masked channels\n",
    "# rgb_image = np.array([loaded_layers[0],loaded_layers[1],loaded_layers[2]])\n",
    "# masked_image = np.array([loaded_layers[4],loaded_layers[5],loaded_layers[6]])\n",
    "# #hsv_image = cv2.cvtColor(np.transpose((loaded_layers[:3]), axes=[1, 2, 0]), cv2.COLOR_RGB2HSV)\n",
    "# hsv_image = np.transpose(cv2.cvtColor(np.transpose((rgb_image), axes=[1, 2, 0]), cv2.COLOR_RGB2HSV), axes=[2, 0, 1])\n",
    "# # show normalized image (range shifted to approximately 0-255, no hard limit though)\n",
    "# plt.figure(figsize=(14,6))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(np.transpose((rgb_image), axes=[1, 2, 0]));\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(np.transpose((hsv_image), axes=[1, 2, 0]));\n",
    "# # plot hue layer\n",
    "# plt.imshow(hsv_image[0], cmap='gray');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hsv_image[0]/360).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.cvtColor(np.transpose((loaded_layers[:3]), axes=[1, 2, 0]), cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to load one of the saved files to see if everything is working\n",
    "# filepath = '/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/pwcw.npy'\n",
    "# loaded_layers = np.load(filepath)\n",
    "# print(loaded_layers[4:].shape)\n",
    "\n",
    "# # # RGB image from individual channels and masked image from masked channels\n",
    "# # rgb_image = np.array(\n",
    "# #         [loaded_layers[0],\n",
    "# #          loaded_layers[1],\n",
    "# #          loaded_layers[2]]\n",
    "# #         )\n",
    "# # masked_image = np.array(\n",
    "# #         [loaded_layers[4],\n",
    "# #          loaded_layers[5],\n",
    "# #          loaded_layers[6]]\n",
    "# #         )\n",
    "# # show normalized image (range shifted to approximately 0-255, no hard limit though)\n",
    "# # plt.figure(figsize=(14,6))\n",
    "# # plt.subplot(121)\n",
    "# # plt.imshow(np.transpose((rgb_image), axes=[1, 2, 0]));\n",
    "# #plt.subplot(122)\n",
    "# #plt.imshow(np.transpose((masked_image), axes=[1, 2, 0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_dataset(data_row):\n",
    "#     record_defaults = ['path', 'target']#tf.constant([0.0], dtype=tf.float32)]\n",
    "#     filename, target = tf.io.decode_csv(data_row, record_defaults)\n",
    "#     #np_image_layers = np.load(filename)\n",
    "#     #image_tensor = tf.convert_to_tensor(np_image_layers, np.float32)\n",
    "#     #\n",
    "#     #image_bytes = tf.io.read_file(filename=filename)\n",
    "#     #label = tf.math.equal(label_string, CLASS_NAMES)\n",
    "#     #return image_tensor, target\n",
    "#     return filename, target\n",
    "\n",
    "# def decode_dataset(data_row):\n",
    "#     record_defaults = ['path', tf.constant([0.0], dtype=tf.float32)]\n",
    "#     filename, target = tf.io.decode_csv(data_row, record_defaults)\n",
    "    \n",
    "#     image_bytes = tf.data.FixedLengthRecordDataset(\n",
    "#         filenames=[filename],\n",
    "#         record_bytes=NUM_TOTAL_VALUES * DTYPE.size, \n",
    "#         header_bytes=128\n",
    "#     )\n",
    "#     #image_bytes = tf.io.read_file(filename=filename)\n",
    "#     ## remove header bytes # (32 bytes for float32, 16 bytes for float64, 64 bytes for float16)\n",
    "#     #image_bytes = image_bytes[32:]\n",
    "\n",
    "#     #np_image_layers = np.load(filename)\n",
    "#     #image_tensor = tf.convert_to_tensor(np_image_layers, np.float32)\n",
    "#     #label = tf.math.equal(label_string, CLASS_NAMES)\n",
    "#     return image_bytes, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import image_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.load(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.TextLineDataset(filenames=TRAIN_PATH)\n",
    "# dataset = dataset.map(image_modeling.decode_dataset)\n",
    "# #dataset = dataset.map(decode_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bytes = tf.io.read_file(test_path)\n",
    "# remove header bytes # (32 bytes for float32, 16 bytes for float64, 64 bytes for float16)\n",
    "#image_bytes = image_bytes[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bytes.numpy()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bytes[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bytes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the numpy files\n",
    "# def numpy_loader(filename):\n",
    "#   image_array = np.load(str(filename))\n",
    "#   return image_array\n",
    "\n",
    "# def wrapper_func(filename, target):\n",
    "#     img = tf.numpy_function(numpy_loader, [filename], tf.float32)\n",
    "#     return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"b'/Users/markus/neuefische/tick-tick-bloom/data/sat_images/image_arrays_8_layer/qone.npy'\"\n",
    "# test[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(np.load(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.numpy_function(numpy_loader, [test_path], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build and train our model using the prior defined functions \n",
    "#model = linear_model()\n",
    "#trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6828e5b3cdea7405\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6828e5b3cdea7405\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the testing function for our model\n",
    "#test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now let us move on to a CNN model. \n",
    "def cnn_model():\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #model.add(tf.keras.layers.InputLayer(\n",
    "    #                                    input_shape=IMG_SHAPE,\n",
    "                                        #data_format=\"channels_first\",  \n",
    "                                        #input_shape=[HEIGHT, WIDTH, 3], \n",
    "                                        #name='image'\n",
    "    #                                    ))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=[5, 5], padding=\"same\", activation=\"relu\", input_shape=IMG_SHAPE, data_format=\"channels_first\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    # model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    # model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    # model.add(tf.keras.layers.Dropout(0.25))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    # # model.add(tf.keras.layers.Dropout(0.25))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=[5, 5], padding=\"same\", activation=\"relu\"))\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2))\n",
    "    # # model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation=\"relu\"))#, kernel_regularizer=tf.keras.regularizers.L1(0.01)))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=None))\n",
    "\n",
    "    # model = tf.keras.Sequential()\n",
    "    # #model.add(tf.keras.layers.InputLayer(input_shape=IMG_SHAPE, name='image'))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=[3, 3], activation='relu', input_shape=IMG_SHAPE, data_format='channels_first'))#, padding='same'))\n",
    "    # # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=[3, 3], activation='relu', padding='same'))\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=[3, 3], activation='relu', padding='same'))\n",
    "    # # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=9, kernel_size=[3, 3], activation='relu', padding='same'))\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=[3, 3], activation='relu', padding='same'))\n",
    "    # # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Conv2D(filters=10, kernel_size=[3, 3], activation='relu', padding='same'))\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(2))\n",
    "    # model.add(tf.keras.layers.Flatten())\n",
    "    # model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dense(units=1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 19:06:11.258823: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-03 19:06:11.258981: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 10, 128, 128)      1010      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 64, 128)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 64, 20)         64020     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 32, 20)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 32, 20)         10020     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 16, 20)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               96300     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,651\n",
      "Trainable params: 171,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 19:06:11.579327: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-03 19:06:11.907321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    427/Unknown - 48s 112ms/step - loss: 54205209378816.0000 - root_mean_squared_error: 7362419.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 19:07:00.480596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 50s 117ms/step - loss: 54205209378816.0000 - root_mean_squared_error: 7362419.0000 - val_loss: 7466964221952.0000 - val_root_mean_squared_error: 2732574.5000\n",
      "Epoch 2/10\n",
      "427/427 [==============================] - 49s 115ms/step - loss: 53895480999936.0000 - root_mean_squared_error: 7341354.0000 - val_loss: 7472164634624.0000 - val_root_mean_squared_error: 2733526.0000\n",
      "Epoch 3/10\n",
      "427/427 [==============================] - 49s 115ms/step - loss: 53894373703680.0000 - root_mean_squared_error: 7341279.0000 - val_loss: 7471239266304.0000 - val_root_mean_squared_error: 2733356.7500\n",
      "Epoch 4/10\n",
      "427/427 [==============================] - 50s 116ms/step - loss: 53893127995392.0000 - root_mean_squared_error: 7341193.5000 - val_loss: 7469775454208.0000 - val_root_mean_squared_error: 2733089.0000\n",
      "Epoch 5/10\n",
      "427/427 [==============================] - 50s 116ms/step - loss: 53891936813056.0000 - root_mean_squared_error: 7341112.5000 - val_loss: 7468068896768.0000 - val_root_mean_squared_error: 2732776.7500\n",
      "Epoch 6/10\n",
      "427/427 [==============================] - 50s 117ms/step - loss: 53890674327552.0000 - root_mean_squared_error: 7341027.0000 - val_loss: 7466369155072.0000 - val_root_mean_squared_error: 2732465.7500\n",
      "Epoch 7/10\n",
      "427/427 [==============================] - 50s 116ms/step - loss: 53889541865472.0000 - root_mean_squared_error: 7340949.5000 - val_loss: 7466223403008.0000 - val_root_mean_squared_error: 2732439.0000\n",
      "Epoch 8/10\n",
      "427/427 [==============================] - 52s 123ms/step - loss: 53888321323008.0000 - root_mean_squared_error: 7340867.0000 - val_loss: 7465264480256.0000 - val_root_mean_squared_error: 2732263.7500\n",
      "Epoch 9/10\n",
      "427/427 [==============================] - 49s 116ms/step - loss: 53887272747008.0000 - root_mean_squared_error: 7340795.0000 - val_loss: 7464367947776.0000 - val_root_mean_squared_error: 2732099.5000\n",
      "Epoch 10/10\n",
      "427/427 [==============================] - 49s 116ms/step - loss: 53886312251392.0000 - root_mean_squared_error: 7340730.0000 - val_loss: 7463417413632.0000 - val_root_mean_squared_error: 2731925.5000\n"
     ]
    }
   ],
   "source": [
    "# Let us fit the convolutional neural network\n",
    "trained_model = train_and_evaluate(model, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706/1706 [==============================] - 12s 7ms/step - loss: 28885919989760.0000 - root_mean_squared_error: 5374562.5000\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8 (main, Nov 14 2022, 14:26:12) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9a535db1be498f54965b2068ed843f3fbab24c395f5b78d57e51cad9890591f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
